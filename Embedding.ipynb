{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\AriZu\\.conda\\envs\\pytorchstudy\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置路径\n",
    "chunk_folder = \"Chunk_file_folder\"\n",
    "vector_store_path = \"vector_store\"\n",
    "\n",
    "# 读取所有 chunk 文件\n",
    "chunk_files = [f for f in os.listdir(chunk_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Alibaba-NLP/gte-multilingual-base were not used when initializing NewModel: {'classifier.bias', 'classifier.weight'}\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer(\"Alibaba-NLP/gte-multilingual-base\", trust_remote_code=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=vector_store_path)\n",
    "collection = client.get_or_create_collection(name=\"psychology_chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk_file(file_path): \n",
    "    \"\"\"读取 chunk 文件并返回文本列表，保持原始换行结构\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        chunks = []\n",
    "        current_chunk = []\n",
    "        for line in f:\n",
    "            if line.startswith(\"chunk \"):  # 检测新 chunk 起始\n",
    "                if current_chunk:\n",
    "                    chunks.append(\"\\n\".join(current_chunk))  # 保持原始换行\n",
    "                    current_chunk = []\n",
    "            elif line.strip() and not line.startswith(\"-\"):\n",
    "                current_chunk.append(line.strip())  \n",
    "        if current_chunk:\n",
    "            chunks.append(\"\\n\".join(current_chunk))  # 最后一个 chunk 也要加入\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def process_table_file(file_path):\n",
    "    \"\"\"读取 _tables.txt 文件并转换为 Markdown 表格格式\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        table_texts = []\n",
    "        current_table = []\n",
    "        table_headers = None\n",
    "\n",
    "        for line in f:\n",
    "            if re.fullmatch(r\"=+\", line.strip()):  # 识别表格分隔符\n",
    "                if current_table:\n",
    "                    # 处理表格：使用 Markdown 格式\n",
    "                    table_str = \"\\n\".join([\" | \".join(row) for row in current_table])\n",
    "                    if table_headers:\n",
    "                        table_str = table_headers + \"\\n\" + \"-\" * len(table_headers) + \"\\n\" + table_str\n",
    "                    table_texts.append(table_str)\n",
    "                    current_table = []\n",
    "            elif line.strip():\n",
    "                cols = line.strip().split()  # 可能是列数据\n",
    "                if not table_headers:\n",
    "                    table_headers = \" | \".join(cols)  # 记录表头\n",
    "                else:\n",
    "                    current_table.append(cols)\n",
    "\n",
    "        if current_table:\n",
    "            table_str = \"\\n\".join([\" | \".join(row) for row in current_table])\n",
    "            if table_headers:\n",
    "                table_str = table_headers + \"\\n\" + \"-\" * len(table_headers) + \"\\n\" + table_str\n",
    "            table_texts.append(table_str)\n",
    "\n",
    "    return table_texts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Complex PTSD_ From Surviving to Thriving_tables.txt\n",
      "Finished: Complex PTSD_ From Surviving to Thriving_tables.txt, stored 7 chunks in vector store\n",
      "Processing: Complex PTSD_ From Surviving to Thriving_text.txt\n",
      "Finished: Complex PTSD_ From Surviving to Thriving_text.txt, stored 4549 chunks in vector store\n",
      "Processing: GPMHSC-Suicide-prevention-and-first-aid-resource-for-GPs_tables.txt\n",
      "Finished: GPMHSC-Suicide-prevention-and-first-aid-resource-for-GPs_tables.txt, stored 7 chunks in vector store\n",
      "Processing: GPMHSC-Suicide-prevention-and-first-aid-resource-for-GPs_text.txt\n",
      "Finished: GPMHSC-Suicide-prevention-and-first-aid-resource-for-GPs_text.txt, stored 156 chunks in vector store\n",
      "Processing: therapists_guide_to_brief_cbtmanual_tables.txt\n",
      "Finished: therapists_guide_to_brief_cbtmanual_tables.txt, stored 24 chunks in vector store\n",
      "Processing: therapists_guide_to_brief_cbtmanual_text.txt\n",
      "Finished: therapists_guide_to_brief_cbtmanual_text.txt, stored 2116 chunks in vector store\n",
      "All done! Successfully stored 6859 chunks. Ready for retrieval.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 处理所有 chunk 文件，并向量化存储\n",
    "success_count = 0\n",
    "\n",
    "for chunk_file in chunk_files:\n",
    "    chunk_path = os.path.join(chunk_folder, chunk_file)\n",
    "    print(f\"Processing: {chunk_file}\")\n",
    "\n",
    "    # 根据文件类型处理不同的 chunk 文件\n",
    "    if chunk_file.endswith(\"_text.txt\"):  \n",
    "        chunks = process_chunk_file(chunk_path)\n",
    "    elif chunk_file.endswith(\"_tables.txt\"):  \n",
    "        chunks = process_table_file(chunk_path)\n",
    "    else:\n",
    "        continue  # 其他文件忽略\n",
    "\n",
    "    # 如果 chunks 为空，跳过处理\n",
    "    if not chunks:\n",
    "        print(f\"Warning: {chunk_file} has no valid content. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # 生成 embedding\n",
    "        chunk_embeddings = embedding_model.encode(chunks)\n",
    "\n",
    "        # 存入 ChromaDB\n",
    "        for i, (chunk, embedding) in enumerate(zip(chunks, chunk_embeddings)):\n",
    "            collection.add(\n",
    "                ids=[f\"{chunk_file}_{i}\"],\n",
    "                embeddings=[embedding.tolist()],\n",
    "                metadatas=[{\"text\": chunk, \"source\": chunk_file}]\n",
    "            )\n",
    "            success_count += 1  # 记录成功存储的条数\n",
    "\n",
    "        print(f\"Finished: {chunk_file}, stored {len(chunks)} chunks in vector store\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {chunk_file}: {str(e)}\")\n",
    "\n",
    "print(f\"All done! Successfully stored {success_count} chunks. Ready for retrieval.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 2116\n",
      "Average chunk length: 19.66 words\n",
      "Shortest chunk: 1 words\n",
      "Longest chunk: 336 words\n",
      "Chunks with < 50 words: 1987 (93.90%)\n"
     ]
    }
   ],
   "source": [
    "# 计算 chunk 长度分布\n",
    "chunk_lengths = [len(chunk.split()) for chunk in chunks]\n",
    "\n",
    "# 打印一些统计信息\n",
    "print(f\"Total chunks: {len(chunk_lengths)}\")\n",
    "print(f\"Average chunk length: {sum(chunk_lengths) / len(chunk_lengths):.2f} words\")\n",
    "print(f\"Shortest chunk: {min(chunk_lengths)} words\")\n",
    "print(f\"Longest chunk: {max(chunk_lengths)} words\")\n",
    "\n",
    "# 如果有很多 chunk 低于 50 个单词，可能需要调整切分\n",
    "short_chunks = [length for length in chunk_lengths if length < 50]\n",
    "print(f\"Chunks with < 50 words: {len(short_chunks)} ({len(short_chunks) / len(chunk_lengths) * 100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Top 5 Retrieved Chunks ====\n",
      "\n",
      "Result 1 (Score: 0.4265):\n",
      "We must renounce unconscious outer\n",
      "critic strategies such as: [1] “I will use angry criticism to make you afraid of me, so I can be safe\n",
      "from you”; [2] “Why should I bother with people when everyone is so selfish and corrupt” [all-\n",
      "or-none thinking];\n",
      "\n",
      "Result 2 (Score: 0.4483):\n",
      "Just as the inner critic transmutes unreleased anger into self-hate, the outer critic uses it to\n",
      "control and /or push others away.\n",
      "\n",
      "Result 3 (Score: 0.4679):\n",
      "This is the anger-empowered thought-stopping of shielding yourself\n",
      "from inner critic attacks.\n",
      "\n",
      "Result 4 (Score: 0.4707):\n",
      "8. Resist the Inner Critic’s Drasticizing and Catastrophizing.\n",
      "\n",
      "Result 5 (Score: 0.4707):\n",
      "8. Resist the Inner Critic’s Drasticizing and Catastrophizing.\n",
      "\n",
      "Result 6 (Score: 0.4768):\n",
      "Increasing resistance to the critic\n",
      "3. Increased Mindfulness about flashbacks or inner critic attacks\n",
      "4.\n",
      "\n",
      "Result 7 (Score: 0.4840):\n",
      "[the toxic\n",
      "shame of the inner critic].\n",
      "\n",
      "Result 8 (Score: 0.4890):\n",
      "As you do, you\n",
      "become more mindful of your inner critic’s hard-to-detect triggers.\n",
      "\n",
      "Result 9 (Score: 0.4939):\n",
      "In assisting others to manage\n",
      "flashbacks, the most common help I offer is to encourage them to challenge the alarmist and\n",
      "perfectionistic programming of the inner critic.\n",
      "\n",
      "Result 10 (Score: 0.4960):\n",
      "On the internal dimension, we decrease the habit of repetitively perpetrating our parents’ abuse\n",
      "against ourselves by staunchly confronting the inner critic. This then allows us to become more\n",
      "mindful on the external dimension when others reenact our parents’ mistreatment.\n",
      "================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_text = \"如何管理内心的批评者？\"  # 你要查询的文本\n",
    "query_embedding = embedding_model.encode([query_text])  # 计算查询文本的 embedding\n",
    "\n",
    "# 执行向量检索\n",
    "results = collection.query(\n",
    "    query_embeddings=query_embedding.tolist(),\n",
    "    n_results=10  # 取回最相似的 5 条记录\n",
    ")\n",
    "\n",
    "# 打印查询结果\n",
    "print(\"\\n==== Top 5 Retrieved Chunks ====\")\n",
    "for i, (retrieved_text, score) in enumerate(zip(results[\"metadatas\"][0], results[\"distances\"][0])):\n",
    "    print(f\"\\nResult {i+1} (Score: {score:.4f}):\")\n",
    "    print(retrieved_text[\"text\"])\n",
    "print(\"================================\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchstudy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
