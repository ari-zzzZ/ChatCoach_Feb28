{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\AriZu\\.conda\\envs\\pytorchstudy\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置路径\n",
    "chunk_folder = \"Chunk_file_folder\"\n",
    "vector_store_path = \"vector_store\"\n",
    "\n",
    "# 读取所有 chunk 文件\n",
    "chunk_files = [f for f in os.listdir(chunk_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Alibaba-NLP/gte-multilingual-base were not used when initializing NewModel: {'classifier.weight', 'classifier.bias'}\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer(\"Alibaba-NLP/gte-multilingual-base\", trust_remote_code=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=vector_store_path)\n",
    "collection = client.get_or_create_collection(name=\"psychology_chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk_file(file_path): \n",
    "    \"\"\"读取 chunk 文件并返回文本列表，保持原始换行结构\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        chunks = []\n",
    "        current_chunk = []\n",
    "        for line in f:\n",
    "            if line.startswith(\"chunk \"):  # 检测新 chunk 起始\n",
    "                if current_chunk:\n",
    "                    chunks.append(\"\\n\".join(current_chunk))  # 保持原始换行\n",
    "                    current_chunk = []\n",
    "            elif line.strip() and not line.startswith(\"-\"):\n",
    "                current_chunk.append(line.strip())  \n",
    "        if current_chunk:\n",
    "            chunks.append(\"\\n\".join(current_chunk))  # 最后一个 chunk 也要加入\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def process_table_file(file_path):\n",
    "    \"\"\"读取 _tables.txt 文件并转换为 Markdown 表格格式\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        table_texts = []\n",
    "        current_table = []\n",
    "        table_headers = None\n",
    "\n",
    "        for line in f:\n",
    "            if re.fullmatch(r\"=+\", line.strip()):  # 识别表格分隔符\n",
    "                if current_table:\n",
    "                    # 处理表格：使用 Markdown 格式\n",
    "                    table_str = \"\\n\".join([\" | \".join(row) for row in current_table])\n",
    "                    if table_headers:\n",
    "                        table_str = table_headers + \"\\n\" + \"-\" * len(table_headers) + \"\\n\" + table_str\n",
    "                    table_texts.append(table_str)\n",
    "                    current_table = []\n",
    "            elif line.strip():\n",
    "                cols = line.strip().split()  # 可能是列数据\n",
    "                if not table_headers:\n",
    "                    table_headers = \" | \".join(cols)  # 记录表头\n",
    "                else:\n",
    "                    current_table.append(cols)\n",
    "\n",
    "        if current_table:\n",
    "            table_str = \"\\n\".join([\" | \".join(row) for row in current_table])\n",
    "            if table_headers:\n",
    "                table_str = table_headers + \"\\n\" + \"-\" * len(table_headers) + \"\\n\" + table_str\n",
    "            table_texts.append(table_str)\n",
    "\n",
    "    return table_texts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Complex PTSD_ From Surviving to Thriving_tables.txt\n",
      "Processing: Complex PTSD_ From Surviving to Thriving_text.txt\n",
      "Finished: Complex PTSD_ From Surviving to Thriving_text.txt, stored 2679 chunks in vector store\n",
      "Processing: GPMHSC-Suicide-prevention-and-first-aid-resource-for-GPs_tables.txt\n",
      "Processing: GPMHSC-Suicide-prevention-and-first-aid-resource-for-GPs_text.txt\n",
      "Finished: GPMHSC-Suicide-prevention-and-first-aid-resource-for-GPs_text.txt, stored 87 chunks in vector store\n",
      "Processing: therapists_guide_to_brief_cbtmanual_tables.txt\n",
      "Processing: therapists_guide_to_brief_cbtmanual_text.txt\n",
      "Finished: therapists_guide_to_brief_cbtmanual_text.txt, stored 1271 chunks in vector store\n",
      "All done! Successfully stored 4037 chunks. Ready for retrieval.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 处理所有 chunk 文件，并向量化存储\n",
    "success_count = 0\n",
    "\n",
    "for chunk_file in chunk_files:\n",
    "    chunk_path = os.path.join(chunk_folder, chunk_file)\n",
    "    print(f\"Processing: {chunk_file}\")\n",
    "\n",
    "    # 根据文件类型处理不同的 chunk 文件\n",
    "    if chunk_file.endswith(\"_text.txt\"):  \n",
    "        chunks = process_chunk_file(chunk_path)\n",
    "    #elif chunk_file.endswith(\"_tables.txt\"):  \n",
    "        #chunks = process_table_file(chunk_path)\n",
    "    else:\n",
    "        continue  # 其他文件忽略\n",
    "\n",
    "    # 如果 chunks 为空，跳过处理\n",
    "    if not chunks:\n",
    "        print(f\"Warning: {chunk_file} has no valid content. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # 生成 embedding\n",
    "        chunk_embeddings = embedding_model.encode(chunks)\n",
    "\n",
    "        # 存入 ChromaDB\n",
    "        for i, (chunk, embedding) in enumerate(zip(chunks, chunk_embeddings)):\n",
    "            collection.add(\n",
    "                ids=[f\"{chunk_file}_{i}\"],\n",
    "                embeddings=[embedding.tolist()],\n",
    "                metadatas=[{\"text\": chunk, \"source\": chunk_file}]\n",
    "            )\n",
    "            success_count += 1  # 记录成功存储的条数\n",
    "\n",
    "        print(f\"Finished: {chunk_file}, stored {len(chunks)} chunks in vector store\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {chunk_file}: {str(e)}\")\n",
    "\n",
    "print(f\"All done! Successfully stored {success_count} chunks. Ready for retrieval.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 1271\n",
      "Average chunk length: 32.73 words\n",
      "Shortest chunk: 1 words\n",
      "Longest chunk: 427 words\n",
      "Chunks with < 50 words: 969 (76.24%)\n"
     ]
    }
   ],
   "source": [
    "# 计算 chunk 长度分布\n",
    "chunk_lengths = [len(chunk.split()) for chunk in chunks]\n",
    "\n",
    "# 打印一些统计信息\n",
    "print(f\"Total chunks: {len(chunk_lengths)}\")\n",
    "print(f\"Average chunk length: {sum(chunk_lengths) / len(chunk_lengths):.2f} words\")\n",
    "print(f\"Shortest chunk: {min(chunk_lengths)} words\")\n",
    "print(f\"Longest chunk: {max(chunk_lengths)} words\")\n",
    "\n",
    "# 如果有很多 chunk 低于 50 个单词，可能需要调整切分\n",
    "short_chunks = [length for length in chunk_lengths if length < 50]\n",
    "print(f\"Chunks with < 50 words: {len(short_chunks)} ({len(short_chunks) / len(chunk_lengths) * 100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Top 5 Retrieved Chunks ====\n",
      "\n",
      "Result 1 (Score: 0.6367):\n",
      "My therapist’s modeling that anger, sadness, fear, and depression were emotions that could\n",
      "be healthily expressed helped me to renounce the pain-repressing, emotional perfectionism in\n",
      "which I was mired.\n",
      "\n",
      "Result 2 (Score: 0.6637):\n",
      "Patients with problems that are largely emotional; for example, a person who feels\n",
      "incompetent at work and often feels that others are overly critical may be reacting\n",
      "to emotions (e.g., depression).\n",
      "\n",
      "Result 3 (Score: 0.6928):\n",
      "Unpredictable shifts in your emotional weather are typically problematic in Cptsd.\n",
      "\n",
      "Result 4 (Score: 0.7031):\n",
      "Emotional intelligence about the healthy and\n",
      "functional aspects of anger, sadness, and fear lies fallow. De-Minimizing Emotional Abandonment\n",
      "As with physical abuse, effective work on the wounds of verbal and emotional abuse can\n",
      "sometimes open the door to de-minimizing the awful impact of emotional neglect. I sometimes\n",
      "feel the most for my clients who were “only” neglected, because it is so difficult to see neglect as\n",
      "hard core evidence.\n",
      "\n",
      "Result 5 (Score: 0.7096):\n",
      "Most of the time, disapproval is okay with me. MANAGING EMOTIONAL FLASHBACKS\n",
      "Emotional flashbacks are intensely disturbing regressions [“amygdala hijackings”] to the\n",
      "overwhelming feeling-states of your childhood abandonment. When you are stuck in a flashback,\n",
      "fear, shame and/or depression can dominate your experience. These are some common experiences of being in an emotional flashback. You feel little,\n",
      "fragile and helpless.\n",
      "\n",
      "Result 6 (Score: 0.7184):\n",
      "In this vein, it is my opinion that techniques like EMDR\n",
      "\n",
      "Result 7 (Score: 0.7216):\n",
      "How ironic that this typically invokes a feeling-sense in me that the worst thing that\n",
      "happened to me, by far, was growing up so emotionally abandoned. In fact, it was not until I\n",
      "learned to assign the pain of numerous current time emotional flashbacks to the abject loneliness\n",
      "of my childhood, that I was able to work effectively on the repetition compulsion that lead me\n",
      "into so many neglectful relationships. And once again this is not to deny or minimize the C-ptsd-inducing traumatization that does\n",
      "come from each and every type of abuse; physical, sexual, verbal and emotional. Practicing Vulnerability\n",
      "Emotional abandonment is healed by the type of real intimacy that we have been discussing. And\n",
      "once again real intimacy depends on us showing up in times of vulnerability.\n",
      "\n",
      "Result 8 (Score: 0.7219):\n",
      "Refer to intervention techniques unique to the\n",
      "type of therapy being provided (e.g., CBT, psychodynamic, interpersonal).\n",
      "\n",
      "Result 9 (Score: 0.7223):\n",
      "Cognitive therapy supervision.\n",
      "\n",
      "Result 10 (Score: 0.7278):\n",
      "Here are two examples of this. When a hurt person only knows how to express anger, his\n",
      "repressed sadness unconsciously seeps into his anger in a way that makes him sound like a\n",
      "martyr or someone with delusions of persecution. Because there is no substantial release of his\n",
      "sadness, no amount of whining brings him relief, and he can angrily whine endlessly in a way\n",
      "that exhausts his listener’s empathy. Similarly when a hurt person is only able to cry, repressed\n",
      "anger tinges her sadness and makes it sound like irritable and interminable bellyaching. One of\n",
      "my clients calls this “anger coming through a very small hole.”\n",
      "================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_text = \"In psychological therapy, emotional regulation is a crucial aspect. Patients often experience anxiety, depression, or anger, which may stem from childhood trauma, workplace stress, or interpersonal conflicts.Common emotional regulation techniques include,Mindfulness Meditation: Focusing on the present moment to reduce anxiety about the past and future.\"  # 你要查询的文本\n",
    "query_embedding = embedding_model.encode([query_text])  # 计算查询文本的 embedding\n",
    "\n",
    "# 执行向量检索\n",
    "results = collection.query(\n",
    "    query_embeddings=query_embedding.tolist(),\n",
    "    n_results=10  # 取回最相似的 5 条记录\n",
    ")\n",
    "\n",
    "# 打印查询结果\n",
    "print(\"\\n==== Top 5 Retrieved Chunks ====\")\n",
    "for i, (retrieved_text, score) in enumerate(zip(results[\"metadatas\"][0], results[\"distances\"][0])):\n",
    "    print(f\"\\nResult {i+1} (Score: {score:.4f}):\")\n",
    "    print(retrieved_text[\"text\"])\n",
    "print(\"================================\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchstudy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
